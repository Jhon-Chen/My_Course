{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单体验代码演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模块\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一张图\n",
    "g = tf.Graph()\n",
    "# 使用这张图，注意，会话默认使用的不是这张图\n",
    "with g.as_default():\n",
    "    con_g = tf.constant(4.0)\n",
    "#     print(con_g.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现加法\n",
    "con1 = tf.constant(11.0, name = 'con1')\n",
    "con2 = tf.constant(12.0, name = 'con2')\n",
    "\n",
    "sum_ = tf.add(con1, con2, name = 'sum')\n",
    "\n",
    "# 当这个数据在图中没有明确定义好数据的内容\n",
    "plt = tf.placeholder(tf.float32, shape=[None, 2])  # 指定数据类型，数据形状,不固定用None\n",
    "# 在run时使用feed来传入数据\n",
    "\n",
    "#print(con1, con2, sum_)\n",
    "# print(tf.get_default_graph())\n",
    "# print(g) # 一个程序里可以定义多张图，他们的地址不同\n",
    "# print(sum_)  TensorFlow的运行并不是指定的命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "# 运行需要使用会话运行\n",
    "with tf.Session(config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)) as sess:\n",
    "    print(sess.run(plt, feed_dict={plt: [[1, 2], [3, 4]]})) # 这个猎豹是fetches\n",
    "#     print(con1.graph)\n",
    "\n",
    "# 在会话中序列化图到events文件(\"存储路径\"，graph = 指定的图)\n",
    "#     tf.summary.FileWriter(\"C:\\\\Users\\\\Administrator\\\\Git\\\\CFturb\\\\Deep_Learning\\\\\", graph = sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow结构分析\n",
    "\n",
    "* **一个构建图的阶段**：图（程序）的定义\n",
    "    * 张量：TensorFlow中的基本数据对象\n",
    "    * 节点（OP）：大部分时候是指运行操作（有时也与其他操作）\n",
    "* **一个执行图的阶段**：通过会话去运行程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图与Tensorboard\n",
    "\n",
    "* 图包含了一组**tf.Operation**代表计算单元的对象和**tf.Tensor**代表计算单元之间流动的数据。\n",
    "\n",
    "* TensorBoard可视化视为更方便的理解、优化与调试。\n",
    "\n",
    "1. 将程序序列化道一个events文件\n",
    "    * 生成一个文件名称格式为events.out.tfevents.{timestamp}.{hostname}\n",
    "\n",
    "2. 启动TensorBoard\n",
    "    * `tensorboard --logdir=\"/tmp/tensorflow/summary/test/\"` \n",
    "    * 在浏览器中打开TensorBoard的图页面127.0.0.1:6060，会看到与一下图形类似的图，在GRAPHS模块我们可以看到一下图结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OP节点\n",
    "\n",
    "![image41b67.png](https://miao.su/images/2019/10/12/image41b67.png)\n",
    "\n",
    "* OP有一个名字：在整个TensorFlow程序当中全局唯一\n",
    "\n",
    "* 通过name参数，修改指令名称，便于查看图当中的OP内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 会话\n",
    "\n",
    "会话是一个运行TensorFlow operation的类，会话包含以下两种打开方式：\n",
    "* `tf.Session`：用于完整的程序当中\n",
    "\n",
    "* `tf.InteractiveSession`：用于交互式上下文中的TensorFlow，例如shell\n",
    "> 1. TensorFlow使用`tf.Session`类来表示客户端程序（通常为Python程序，但与提供了使用其他语言的类似接口）与C++运行时之间的连接\n",
    "> 2. `tf.Session`对象使用分布式TensorFlow运行时提供对本地计算机中的设备和远程设备的访问权限\n",
    "> 3. 在交互界面时，可以使用`tf.InteractiveSession().eval()`运行程序\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化\n",
    "\n",
    "**`init(target=', graph=None, config=None)`**\n",
    "\n",
    "1. 会话一般会使用很多的资源，在程序运行过后我们往往需要去释放资源，所以一般有两种方法：\n",
    "\n",
    "    `sess.run() ... sess.close()`  # 这样写很麻烦\n",
    "\n",
    "    `with tf.Session as sess: ......`  # 可以使用上下文管理器，这样不会遗忘代码也更加简洁\n",
    "\n",
    "2. 会话运行的是默认这张图，所以要运行的OP必须是这张图当中的\n",
    "\n",
    "初始化的几个参数：\n",
    "\n",
    "* target：如果此参数留空（默认），会话将仅使用本地计算机中的设备。可以指定 `grpc://网址`，以便指定TensorFlow服务器的地址，这使得会话可以访问该服务器控制的计算机上的所有设备。\n",
    "\n",
    "* grapg：默认情况下，新的`tf.Session`将绑定到当前的默认图，并且只能在当前的默认图中operation。\n",
    "\n",
    "* config：此参数允许您指定一个`tf.ConfigProto`以便控制会话的行为。例如，ConfigProto协议用于打印设备使用信息。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会话的`run()`\n",
    "\n",
    "`run(fetches, feed_dict=None, options=None, run_metadata=None)`\n",
    "\n",
    "* 通过使用`sess.run()`来运行operation\n",
    "\n",
    "* `sess.run([xxx, xxx, xxx])`利用传入一个列表，可以一次运算多个结果 \n",
    "\n",
    "* 会话`sess.run()`中的参数不能是非OP，tensor对象\n",
    "\n",
    "run的参数：\n",
    "* fetches：运行多个使用列表\n",
    "\n",
    "* feed_dict：运行的时候提供数据，一般不确定数据形状时，可以结合placeholder使用。用在训练的时候实时提供要训练的批次数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**常见的错误：**\n",
    "1. RuntimeError：如果这个Session是无效状态（例如已关闭）\n",
    "\n",
    "2. TypeError：如果fetches或者feed_dict键的类型不合适\n",
    "\n",
    "3. ValueError：如果fetches或feed_dict键无效或引用Tensor键不存在"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量\n",
    "\n",
    "在编写TensorFlow程序时，程序传递和运算的主要目标是tf.Tensor。\n",
    "\n",
    "TensorFlow的张量就是一个n维数组，类型为tf.Tensor。Tensor具有以下两个重要的属性\n",
    "\n",
    "* type：数据类型\n",
    "\n",
    "* shape：形状（阶）\n",
    "\n",
    "![imagea0902.png](https://miao.su/images/2019/10/13/imagea0902.png)\n",
    "\n",
    "![image94a59.png](https://miao.su/images/2019/10/13/image94a59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建张量的指令\n",
    "\n",
    "**创建固定值张量：（和NumPy类似）：**\n",
    "* **`tf.zero(shape, dtype=tf.float32, name=None)`**\n",
    "\n",
    "    创建所有元素设置为零的张量。此操作返回一个dtype具有形状shape和所有元素设置为零的类型的张量。\n",
    "    \n",
    "* `tf.zeros_like(tensor, dtype=None, name=None)`\n",
    "\n",
    "    给tensor定单张量（），此操作返回tensor与所有元素设置为零相同的类型和形状的张量。\n",
    "    \n",
    "* **`tf.ones(shape, dtype=tf.float32, name=None)`**\n",
    "\n",
    "    创建一个所有元素设置为1的张量，此操作返回一个类型的张量，dtype形状shape和所有元素设置为1。\n",
    "    \n",
    "* `tf.ones_like(tensor, dtype=None, name=None)`\n",
    "\n",
    "    给tensor定单张量（），此操作返回tensor与所有元素设置为1相同的类型和形状的张量。\n",
    "    \n",
    "* `tf.fill(dims, value, name=None)`\n",
    "\n",
    "    创建一个填充了标量值的张量，此操作创建了一个张量的形状dims并填充它value。\n",
    "    \n",
    "* **`tf.constant(value, dtype=None, shape=None, name='Const')`**\n",
    "\n",
    "    创建一个常数张量。\n",
    "    \n",
    "\n",
    "![imagea3dd9.png](https://miao.su/images/2019/10/13/imagea3dd9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建随机张量：**\n",
    "\n",
    "一般我们经常使用的随机函数`Math.random()`产生的是服从均匀分布的随机数，能够模拟等概率出现的情况，但是现实生活中更多的是正态分布：\n",
    "\n",
    "`tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`\n",
    "\n",
    "从截断的正态分布中输出随机值，和上面一样，但是所有数字都不超过两个标准差：\n",
    "\n",
    "`tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`\n",
    "\n",
    "从正态分布中输出随机的值，由随机正态分布的数字组成的矩阵。\n",
    "\n",
    "* 其他特殊的创建张量的OP\n",
    "    * **`tf.Variable`**\n",
    "    * `tf.placeholder`\n",
    "    \n",
    "![imagea71cf.png](https://miao.su/images/2019/10/13/imagea71cf.png)\n",
    "\n",
    "**注意：参考NumPy中的操作**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量的变换\n",
    "\n",
    "#### 类型变换\n",
    "\n",
    "![image3e292.png](https://miao.su/images/2019/10/13/image3e292.png)\n",
    "\n",
    "* **cast是一种万能的类型转换**\n",
    "![imagefa36c.png](https://miao.su/images/2019/10/13/imagefa36c.png)\n",
    "\n",
    "\n",
    "#### 形状变化\n",
    "\n",
    "TensorFlow的张量具有两种形状变换，动态形状和静态形状\n",
    "\n",
    "* `tf.reshape`\n",
    "* `tf.set_shape`\n",
    "\n",
    "关于动态形状和静态形状必须符合以下规则：\n",
    "* 静态形状\n",
    "\n",
    "    * 转换静态形状的时候，1-D到1-D，2-D到2-D，不能跨阶数改变形状\n",
    "    \n",
    "    * 对于已经固定的张量的静态形状的张量，不能再次设置静态形状\n",
    "    \n",
    "* 动态形状\n",
    "   \n",
    "    * `tf.reshape()`动态创建新张量时，张量的元素个数必须匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(5, 4), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 张量静态形状\n",
    "con1 = tf.constant([[1, 2], [3, 4]]) \n",
    "# con1.set_shape([4,])  这个操作是错误的，因为静态修改不能改形状固定的张量的阶数\n",
    "\n",
    "plt = tf.placeholder(tf.float32, [5, 4]) # 这个是形状不固定的\n",
    "print(plt)\n",
    "plt.set_shape([5, 4])\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(4, 5), dtype=float32) Tensor(\"Placeholder_1:0\", shape=(5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 张量动态形状\n",
    "plt_reshape = tf.reshape(plt, [4, 5])  # 修改时要注意元素的个数匹配\n",
    "print(plt_reshape, plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量的数学运算（略，API使用即用即查）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量OP\n",
    "\n",
    "### 变量\n",
    "\n",
    "TensorFlow变量是表示程序处理的共享持久状态的最佳方法。变量通过`tf.Variable OP`类以及`tf.get_variable()`类进行操作。变量的特点：\n",
    "\n",
    "* 存储持久化\n",
    "\n",
    "* 可修改值\n",
    "\n",
    "* 可指定被训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **创建变量** \n",
    "\n",
    "可以理解为一种特殊的创建张量的操作\n",
    "\n",
    "* `tf.Variable(initial_value=None, trainable=True, collections=None, name=None)`\n",
    "\n",
    "    * initial_value：初始化的值\n",
    "    \n",
    "    * trainable：是否被训练\n",
    "    \n",
    "    * collections：新变量将添加到列出的图的集合中collections,默认为[Granphkeys.GLOBAL_VARIABLES]，如果trainable是True，变量也被添加到图形集合GraphKeys.TRAINABLE_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var_name:0' shape=(2, 3) dtype=float32_ref>\n",
      "[[0.66035503 2.4947057  2.5247521 ]\n",
      " [4.4920955  6.1858177  5.7395473 ]]\n",
      "[[0.66035503 2.4947057  2.5247521 ]\n",
      " [4.4920955  6.1858177  5.7395473 ]]\n"
     ]
    }
   ],
   "source": [
    "# 变量 特殊的创建张量的OP\n",
    "\"\"\"必须手动显式初始化，才能运行值!!!\"\"\"\n",
    "\n",
    "# 实现加法\n",
    "# con1 = tf.constant(11.0, name = 'con1')\n",
    "# con2 = tf.constant(12.0, name = 'con2')\n",
    "\n",
    "# sum_ = tf.add(con1, con2, name = 'sum')\n",
    "\n",
    "var = tf.Variable(tf.random_normal([2, 3], mean=0.0, stddev=1.0), name=\"var_name\")\n",
    "print(var)\n",
    "\n",
    "# 重新赋值一个新的值，形状必须与上面一样\n",
    "# new_var = var.assign([[1, 2, 3], [4, 5, 6]])\n",
    "new_var = var.assign_add([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 显式初始化的OP\n",
    "init_varop = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 在这里运行初始化的OP\n",
    "    # 可以简略写成：sess.run(tf.gloable_variables_initializer())\n",
    "    sess.run(init_varop)\n",
    "    \n",
    "#     file_writer = tf.summary.FileWriter(\"C:\\\\Users\\\\Administrator\\\\Git\\\\CFturb\\\\Deep_Learning\\\\\", graph=sess.graph)\n",
    "    \n",
    "    print(sess.run(new_var))\n",
    "    print(sess.run(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **变量OP：特殊的创建张量值的OP指令**\n",
    "\n",
    "    * 显式初始化：`sess.run(tf.global_variables_initializer())`\n",
    "\n",
    "    * 可以通过assign修改原来的变量OP当中的张量值\n",
    "\n",
    "    * `assign_add`也会修改原来的值，只是这个是在原来的值上加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 命名空间与共享变量\n",
    "\n",
    "共享变量的主要用途是用在一些网络当中的参数共享，由于在TensorFlow中，只要我们定义的OP，name参数指定一样，其实并不是同一个变量。如果想要到达复用的效果，我们就要使用`tf.variable_scope()`结合`tf.get_variable()`一起使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用`tf.variable_scope()`修改OP命名空间\n",
    "\n",
    "* 它会在OP的名字前面增加命名空间的指定名字\n",
    "\n",
    "* 如果一个命名空间中存在名字相同的变量，那么get_variable方法就会报错\n",
    "\n",
    "* 与python不同，TensorFlow会维护所有OP名字的列表，而不是以取得变量名来区分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"my_scope/con1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"my_scope/con1_1:0\", shape=(), dtype=int32)\n",
      "Tensor(\"my_scope/sum:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 自定义一个命名空间\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "    con1 = tf.constant(1, name='con1')\n",
    "    con2 = tf.constant(2, name='con1')\n",
    "    sum_ = tf.add(con1, con2, name = 'sum')\n",
    "    \n",
    "# var = tf.Variable(tf.random_normal([2, 3], mean=0.0, stddev=1.0), name=\"var_name\")\n",
    "with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    sess.run(sum_)\n",
    "    print(con1)\n",
    "    print(con2)\n",
    "    print(sum_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.get_variable共享变量\n",
    "\n",
    "通过tf.get_variable的初始化与Variable参数一样，但是要是实现共享需要打开`tf.variable_scope(\"name\")`中的`reuse=tf.AUTO_REUSE`参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'scope_1_2/var1:0' shape=(2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'scope_1_2/var1_1:0' shape=(3, 3) dtype=float32_ref>\n",
      "<tf.Variable 'scope_1/var2:0' shape=(2, 2) dtype=float32_ref>\n",
      "<tf.Variable 'scope_1/var2:0' shape=(2, 2) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"scope_1\", reuse=tf.AUTO_REUSE):\n",
    "    var = tf.Variable(tf.random_normal([2, 3], mean=0.0, stddev=1.0), name=\"var1\")\n",
    "    var_1 = tf.Variable(tf.random_normal([3, 3], mean=0.0, stddev=1.0), name=\"var1\")\n",
    "    # 使用get_variable\n",
    "    var_2 = tf.get_variable(initializer=tf.random_normal([2, 2], mean=0.0, stddev=1.0), name=\"var2\")\n",
    "    var_3 = tf.get_variable(initializer=tf.random_normal([2, 2], mean=0.0, stddev=1.0), name=\"var2\")\n",
    "    # 注意，initializer参数必须指定，不指定也不能重用\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(var)\n",
    "    print(var_1)\n",
    "    print(var_2)\n",
    "    print(var_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
