{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型初始化的参数权重：0.306833, 偏置为：0.260018\n",
      "第0次模型优化后的参数权重：0.380172, 偏置为：0.371984, 损失为：0.277629\n",
      "第1次模型优化后的参数权重：0.424781, 偏置为：0.442982, 损失为：0.214328\n",
      "第2次模型优化后的参数权重：0.494726, 偏置为：0.524637, 损失为：0.111439\n",
      "第3次模型优化后的参数权重：0.529687, 偏置为：0.580316, 损失为：0.085464\n",
      "第4次模型优化后的参数权重：0.565146, 偏置为：0.624292, 损失为：0.056273\n",
      "第5次模型优化后的参数权重：0.597086, 偏置为：0.660062, 损失为：0.025921\n",
      "第6次模型优化后的参数权重：0.621292, 偏置为：0.689315, 损失为：0.017762\n",
      "第7次模型优化后的参数权重：0.635836, 偏置为：0.709729, 损失为：0.012643\n",
      "第8次模型优化后的参数权重：0.646689, 偏置为：0.726883, 损失为：0.008025\n",
      "第9次模型优化后的参数权重：0.657364, 偏置为：0.741641, 损失为：0.005747\n",
      "第10次模型优化后的参数权重：0.665476, 偏置为：0.753491, 损失为：0.004023\n",
      "第11次模型优化后的参数权重：0.671828, 偏置为：0.762520, 损失为：0.001948\n",
      "第12次模型优化后的参数权重：0.675189, 偏置为：0.768923, 损失为：0.001564\n",
      "第13次模型优化后的参数权重：0.679907, 偏置为：0.774411, 损失为：0.001164\n",
      "第14次模型优化后的参数权重：0.683294, 偏置为：0.779504, 损失为：0.000778\n",
      "第15次模型优化后的参数权重：0.686069, 偏置为：0.783462, 损失为：0.000403\n",
      "第16次模型优化后的参数权重：0.689946, 偏置为：0.786851, 损失为：0.000219\n",
      "第17次模型优化后的参数权重：0.691896, 偏置为：0.789607, 损失为：0.000183\n",
      "第18次模型优化后的参数权重：0.694116, 偏置为：0.791990, 损失为：0.000115\n",
      "第19次模型优化后的参数权重：0.695242, 偏置为：0.793598, 损失为：0.000069\n",
      "第20次模型优化后的参数权重：0.696596, 偏置为：0.795182, 损失为：0.000035\n",
      "第21次模型优化后的参数权重：0.697406, 偏置为：0.796188, 损失为：0.000022\n",
      "第22次模型优化后的参数权重：0.697939, 偏置为：0.796979, 损失为：0.000014\n",
      "第23次模型优化后的参数权重：0.698330, 偏置为：0.797522, 损失为：0.000008\n",
      "第24次模型优化后的参数权重：0.698556, 偏置为：0.797987, 损失为：0.000006\n",
      "第25次模型优化后的参数权重：0.698873, 偏置为：0.798421, 损失为：0.000004\n",
      "第26次模型优化后的参数权重：0.699018, 偏置为：0.798710, 损失为：0.000003\n",
      "第27次模型优化后的参数权重：0.699169, 偏置为：0.798957, 损失为：0.000002\n",
      "第28次模型优化后的参数权重：0.699331, 偏置为：0.799162, 损失为：0.000001\n",
      "第29次模型优化后的参数权重：0.699458, 偏置为：0.799326, 损失为：0.000001\n",
      "第30次模型优化后的参数权重：0.699572, 偏置为：0.799464, 损失为：0.000001\n",
      "第31次模型优化后的参数权重：0.699659, 偏置为：0.799567, 损失为：0.000000\n",
      "第32次模型优化后的参数权重：0.699718, 偏置为：0.799652, 损失为：0.000000\n",
      "第33次模型优化后的参数权重：0.699801, 偏置为：0.799728, 损失为：0.000000\n",
      "第34次模型优化后的参数权重：0.699836, 偏置为：0.799781, 损失为：0.000000\n",
      "第35次模型优化后的参数权重：0.699873, 偏置为：0.799825, 损失为：0.000000\n",
      "第36次模型优化后的参数权重：0.699898, 偏置为：0.799862, 损失为：0.000000\n",
      "第37次模型优化后的参数权重：0.699925, 偏置为：0.799895, 损失为：0.000000\n",
      "第38次模型优化后的参数权重：0.699942, 偏置为：0.799915, 损失为：0.000000\n",
      "第39次模型优化后的参数权重：0.699952, 偏置为：0.799932, 损失为：0.000000\n",
      "第40次模型优化后的参数权重：0.699961, 偏置为：0.799945, 损失为：0.000000\n",
      "第41次模型优化后的参数权重：0.699969, 偏置为：0.799955, 损失为：0.000000\n",
      "第42次模型优化后的参数权重：0.699976, 偏置为：0.799964, 损失为：0.000000\n",
      "第43次模型优化后的参数权重：0.699980, 偏置为：0.799971, 损失为：0.000000\n",
      "第44次模型优化后的参数权重：0.699985, 偏置为：0.799977, 损失为：0.000000\n",
      "第45次模型优化后的参数权重：0.699987, 偏置为：0.799982, 损失为：0.000000\n",
      "第46次模型优化后的参数权重：0.699990, 偏置为：0.799986, 损失为：0.000000\n",
      "第47次模型优化后的参数权重：0.699992, 偏置为：0.799988, 损失为：0.000000\n",
      "第48次模型优化后的参数权重：0.699993, 偏置为：0.799991, 损失为：0.000000\n",
      "第49次模型优化后的参数权重：0.699995, 偏置为：0.799993, 损失为：0.000000\n",
      "第50次模型优化后的参数权重：0.699996, 偏置为：0.799994, 损失为：0.000000\n",
      "第51次模型优化后的参数权重：0.699997, 偏置为：0.799995, 损失为：0.000000\n",
      "第52次模型优化后的参数权重：0.699998, 偏置为：0.799996, 损失为：0.000000\n",
      "第53次模型优化后的参数权重：0.699998, 偏置为：0.799997, 损失为：0.000000\n",
      "第54次模型优化后的参数权重：0.699998, 偏置为：0.799998, 损失为：0.000000\n",
      "第55次模型优化后的参数权重：0.699999, 偏置为：0.799998, 损失为：0.000000\n",
      "第56次模型优化后的参数权重：0.699999, 偏置为：0.799998, 损失为：0.000000\n",
      "第57次模型优化后的参数权重：0.699999, 偏置为：0.799999, 损失为：0.000000\n",
      "第58次模型优化后的参数权重：0.699999, 偏置为：0.799999, 损失为：0.000000\n",
      "第59次模型优化后的参数权重：0.699999, 偏置为：0.799999, 损失为：0.000000\n",
      "第60次模型优化后的参数权重：0.700000, 偏置为：0.799999, 损失为：0.000000\n",
      "第61次模型优化后的参数权重：0.700000, 偏置为：0.799999, 损失为：0.000000\n",
      "第62次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第63次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第64次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第65次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第66次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第67次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第68次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第69次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第70次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第71次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第72次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第73次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第74次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第75次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第76次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第77次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第78次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第79次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第80次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第81次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第82次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第83次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第84次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第85次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第86次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第87次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第88次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第89次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第90次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第91次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第92次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第93次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第94次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第95次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第96次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第97次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第98次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n",
      "第99次模型优化后的参数权重：0.700000, 偏置为：0.800000, 损失为：0.000000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 建立一个线性回归的模型\n",
    "class MyLinearRegression(object):\n",
    "    \"\"\"实现一个线性回归的训练\"\"\"\n",
    "    def __init__(self):\n",
    "        # 自己设定的学习率，如果学习率过大，那损失不会减小反而会增大，一般 0~1\n",
    "        self.learning_rate = 0.1\n",
    "        pass\n",
    "    \n",
    "    def inputs(self):\n",
    "        \"\"\"获取需要训练的数据\"\"\"\n",
    "        # 因为要进行张量运算（矩阵）所以这里特指值定义成二维的\n",
    "        # x:[100, 1]; y_true  x * 0.7 + 0.8\n",
    "        x_data = tf.random_normal(shape=[100, 1], mean=0.0, stddev=1.0, name='x_data')\n",
    "        # 假设不知道这个矩阵\n",
    "        y_true = tf.matmul(x_data, [[0.7]]) + 0.8\n",
    "        return x_data, y_true\n",
    "\n",
    "    def inference(self, feature):\n",
    "        \"\"\"根据数据特征值建立线性回归模型，feature是特征值\"\"\"\n",
    "        # 先定义一个命名空间避免混乱\n",
    "        with tf.variable_scope(\"linear_model\"):\n",
    "            # w,b : x[100, 1] * w + b = y_predict\n",
    "            # 随机初始化权重和偏置，注意，权重和偏置必须使用tf.Variable变量OP去定义，因为只有Variable才能被梯度下降（模型）所训练\n",
    "            # 权重w应该是[1, 1]形状的矩阵，因为它参与了矩阵的乘法\n",
    "            self.weight = tf.Variable(tf.random_normal(shape=[1, 1], mean=0.0, stddev=1.0), name=\"weight\")\n",
    "            # 偏置是直接加的，所以应该是[1]的形状\n",
    "            self.bias = tf.Variable(tf.random_normal(shape=[1], mean=0.0, stddev=1.0), name=\"bias\")\n",
    "            # 建立模型预测\n",
    "            y_predict = tf.matmul(feature, self.weight) + self.bias\n",
    "        return y_predict\n",
    "    \n",
    "    def loss(self, y_true, y_predict):\n",
    "        \"\"\"根据预测值和真实值求出均方误差\"\"\"\n",
    "        # 定义一个命名空间\n",
    "        # sum((y_true-y_predict)^2)mean()\n",
    "        with tf.variable_scope(\"losses\"):\n",
    "            # 求出损失\n",
    "            # tf.reduce_mean()：对列表中的数据求和之后求平均值\n",
    "            loss = tf.reduce_mean(tf.square(y_true - y_predict))       \n",
    "        return loss\n",
    "    \n",
    "    def sgd_op(self, loss):\n",
    "        \"\"\"利用梯度下降优化器去优化损失(优化模型参数)\"\"\"\n",
    "        # 定义一个命名空间\n",
    "        with tf.variable_scope(\"train_op\"):\n",
    "            train_op = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(loss)\n",
    "        return train_op\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"用于训练的函数\"\"\"\n",
    "        # 获取默认的图\n",
    "        g = tf.get_default_graph()\n",
    "        # 在默认的图中进行操作\n",
    "        with g.as_default():\n",
    "            # 进行训练\n",
    "            # 1.获取数据\n",
    "            x_data, y_true = self.inputs()\n",
    "            # 2.利用模型得出预测结果\n",
    "            y_predict = self.inference(x_data)\n",
    "            # 3.损失计算\n",
    "            loss = self.loss(y_true, y_predict)\n",
    "            # 4.优化损失\n",
    "            train_op = self.sgd_op(loss)\n",
    "            \n",
    "            # 开启会话运行训练\n",
    "            with tf.Session() as sess:\n",
    "                # 初始化变量\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                # 打印模型没有训练的初始化的参数\n",
    "                print(\"模型初始化的参数权重：%f, 偏置为：%f\" % (self.weight.eval(), self.bias.eval()))\n",
    "                \n",
    "                \"\"\"由于只训练一次所以没有什么效果，那我们让它训练多次\"\"\"\n",
    "                for i in range(100):\n",
    "                    # 接下来调用运行\n",
    "                    sess.run(train_op)\n",
    "                    # 再打印一遍优化之后的参数 \n",
    "                    print(\"第%d次模型优化后的参数权重：%f, 偏置为：%f, 损失为：%f\" % (i, self.weight.eval(), self.bias.eval(), loss.eval()))\n",
    "        \n",
    "\n",
    "\n",
    "# 运行整个程序\n",
    "if __name__ == '__main__':\n",
    "    lr = MyLinearRegression()\n",
    "    lr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现线性回归\n",
    "1. **学习率、步长和梯度爆炸**\n",
    "    * 学习率不应该设置过大、0~1之间的数，如果过大，导致梯度爆炸（损失、参数优化成nan）\n",
    "    * 学习率越大，达到最终比较好的效果步长越小\n",
    "    * 学习率越小，达到最终比较好的效果步长越大\n",
    "    * 一般选择较小的学习率\n",
    "    \n",
    "2. **在极端条件下，权重的值变得非常大，以至于溢出，导致`NaN`值。以下是梯度爆炸解决方案（深度神经网络当中更容易出现）**\n",
    "    * 重新设计网络\n",
    "    * 调整学习率\n",
    "    * 使用梯度截断（在训练过程中检查和限制梯度的大小）\n",
    "    * 使用激活函数\n",
    "    \n",
    "3. **模型要优化的参数必须选择`tf.Variable`定义，并且指定`trainable`参数为可训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
