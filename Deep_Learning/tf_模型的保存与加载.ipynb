{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'model_dir' is defined twice. First from C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py, Second from C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py.  Description from first occurrence: C:\\Users\\Administrator\\Git\\CFturb\\Deep_Learning\\ckpt\\myregression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2ddda2e0c4f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 定义模型训练的部署\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trans_step\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"训练模型的步数\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_dir\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\Administrator\\\\Git\\\\CFturb\\\\Deep_Learning\\\\ckpt\\\\myregression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"模型保存的路径\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlAGS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m           \u001b[1;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_string\u001b[1;34m(name, default, help, flag_values, **args)\u001b[0m\n\u001b[0;32m    239\u001b[0m   \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m   \u001b[0mDEFINE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[1;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[0;32m     80\u001b[0m   \"\"\"\n\u001b[0;32m     81\u001b[0m   DEFINE_flag(_flag.Flag(parser, serializer, name, default, help, **args),\n\u001b[1;32m---> 82\u001b[1;33m               flag_values, module_name)\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[1;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[0;32m    102\u001b[0m   \u001b[1;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m   \u001b[0mfv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m   \u001b[1;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, name, flag)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDuplicateFlagError\u001b[0m: The flag 'model_dir' is defined twice. First from C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py, Second from C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py.  Description from first occurrence: C:\\Users\\Administrator\\Git\\CFturb\\Deep_Learning\\ckpt\\myregression"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定义模型训练的部署\n",
    "tf.app.flags.DEFINE_integer(\"trans_step\", 0, \"训练模型的步数\")\n",
    "tf.app.flags.DEFINE_string(\"model_dir\", \"C:\\\\Users\\\\Administrator\\\\Git\\\\CFturb\\\\Deep_Learning\\\\ckpt\\\\myregression\", \"模型保存的路径\")\n",
    "\n",
    "FLAGS = tf.app.flags.FlAGS\n",
    "\n",
    "\n",
    "# 建立一个线性回归的模型\n",
    "class MyLinearRegression(object):\n",
    "    \"\"\"实现一个线性回归的训练\"\"\"\n",
    "    def __init__(self):\n",
    "        # 自己设定的学习率，如果学习率过大，那损失不会减小反而会增大，一般 0~1\n",
    "        self.learning_rate = 0.004\n",
    "        pass\n",
    "    \n",
    "    def inputs(self):\n",
    "        \"\"\"获取需要训练的数据\"\"\"\n",
    "        # 因为要进行张量运算（矩阵）所以这里特指值定义成二维的\n",
    "        # x:[100, 1]; y_true  x * 0.7 + 0.8\n",
    "        x_data = tf.random_normal(shape=[100, 1], mean=0.0, stddev=1.0, name='x_data')\n",
    "        # 假设不知道这个矩阵\n",
    "        y_true = tf.matmul(x_data, [[0.7]]) + 0.8\n",
    "        return x_data, y_true\n",
    "\n",
    "    def inference(self, feature):\n",
    "        \"\"\"根据数据特征值建立线性回归模型，feature是特征值\"\"\"\n",
    "        # 先定义一个命名空间避免混乱\n",
    "        with tf.variable_scope(\"linear_model\"):\n",
    "            # w,b : x[100, 1] * w + b = y_predict\n",
    "            # 随机初始化权重和偏置，注意，权重和偏置必须使用tf.Variable变量OP去定义，因为只有Variable才能被梯度下降（模型）所训练\n",
    "            # 权重w应该是[1, 1]形状的矩阵，因为它参与了矩阵的乘法\n",
    "            self.weight = tf.Variable(tf.random_normal(shape=[1, 1], mean=0.0, stddev=1.0), name=\"weight\")\n",
    "            # 偏置是直接加的，所以应该是[1]的形状\n",
    "            self.bias = tf.Variable(tf.random_normal(shape=[1], mean=0.0, stddev=1.0), name=\"bias\")\n",
    "            # 建立模型预测\n",
    "            y_predict = tf.matmul(feature, self.weight) + self.bias\n",
    "        return y_predict\n",
    "    \n",
    "    def loss(self, y_true, y_predict):\n",
    "        \"\"\"根据预测值和真实值求出均方误差\"\"\"\n",
    "        # 定义一个命名空间\n",
    "        # sum((y_true-y_predict)^2)mean()\n",
    "        with tf.variable_scope(\"losses\"):\n",
    "            # 求出损失\n",
    "            # tf.reduce_mean()：对列表中的数据求和之后求平均值\n",
    "            loss = tf.reduce_mean(tf.square(y_true - y_predict))       \n",
    "        return loss\n",
    "    \n",
    "    def sgd_op(self, loss):\n",
    "        \"\"\"利用梯度下降优化器去优化损失(优化模型参数)\"\"\"\n",
    "        # 定义一个命名空间\n",
    "        with tf.variable_scope(\"train_op\"):\n",
    "            train_op = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(loss)\n",
    "        return train_op\n",
    "    \n",
    "    def merge_summary(self, loss):\n",
    "        \"\"\"定义收集张量的函数\"\"\"\n",
    "        # 收集一些单值变量\n",
    "        tf.summary.scalar(\"losses\", loss)\n",
    "        # 收集高维度的张量值\n",
    "        tf.summary.histogram(\"w\", self.weight)\n",
    "        tf.summary.histogram(\"b\", self.bias)\n",
    "        # 合并变量（OP）\n",
    "        merged = tf.summary.merge_all()\n",
    "        return merged\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"用于训练的函数\"\"\"\n",
    "        # 获取默认的图\n",
    "        g = tf.get_default_graph()\n",
    "        # 在默认的图中进行操作\n",
    "        with g.as_default():\n",
    "            # 进行训练\n",
    "            # 1.获取数据\n",
    "            x_data, y_true = self.inputs()\n",
    "            # 2.利用模型得出预测结果\n",
    "            y_predict = self.inference(x_data)\n",
    "            # 3.损失计算\n",
    "            loss = self.loss(y_true, y_predict)\n",
    "            # 4.优化损失\n",
    "            train_op = self.sgd_op(loss)\n",
    "            \n",
    "            # 收集要观察的张量值\n",
    "            merged = self.merge_summary(loss)\n",
    "            \n",
    "            # 定义一个保存文件的 SaverOP\n",
    "            saver = tf.train.Saver()\n",
    "                       \n",
    "            \n",
    "            # 开启会话运行训练\n",
    "            with tf.Session() as sess:\n",
    "                # 初始化变量\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                \n",
    "                # 创建events文件\n",
    "                file_writer = tf.summary.FileWriter(\"C:\\\\Users\\\\Administrator\\\\Git\\\\CFturb\\\\Deep_Learning\\\\tensorboard\\\\\", graph=sess.graph)\n",
    "                \n",
    "                # 打印模型没有训练时的初始化的参数\n",
    "                print(\"模型初始化的参数权重：%f, 偏置为：%f\" % (self.weight.eval(), self.bias.eval()))\n",
    "                \n",
    "                # 加载模型，从模型中导出与当前训练的模型的代码相同的OP操作， 覆盖原来的值\n",
    "                ckpt = tf.train.latest_checkpoint(\"C:\\\\Users\\\\Administrator\\\\Git\\\\CFturb\\\\Deep_Learning\\\\ckpt\\\\myregression.ckpt\")\n",
    "                # 判断模型是否存在\n",
    "                if ckpt:\n",
    "                    saver.restore(sess, ckpt)\n",
    "                \n",
    "                # 第一次加载模型的参数\n",
    "                print(\"第一次加载模型的参数权重：%f, 偏置为：%f\" % (self.weight.eval(), self.bias.eval()))\n",
    "                print(\"以当前加载的参数开始进行训练\")\n",
    "                \n",
    "                \n",
    "                \"\"\"由于只训练一次所以没有什么效果，那我们让它训练多次\"\"\"\n",
    "                for i in range(FLAGS.trans_step):\n",
    "                    # 接下来调用运行\n",
    "                    _, summary = sess.run([train_op, merged])\n",
    "                    # 把summary添加到文件\n",
    "                    file_writer.add_summary(summary, i)\n",
    "                    # 再打印一遍优化之后的参数 \n",
    "                    print(\"第%d次模型优化后的参数权重：%f, 偏置为：%f, 损失为：%f\" % (i, self.weight.eval(), self.bias.eval(), loss.eval()))\n",
    "                    \n",
    "                    # 每隔100步保存一次模型\n",
    "                    if i % 100 == 0:\n",
    "                        # 要指定路径 + 名字\n",
    "                        saver.save(sess, FLAGS.model_dir)\n",
    "\n",
    "\n",
    "# 运行整个程序\n",
    "if __name__ == '__main__':\n",
    "    lr = MyLinearRegression()\n",
    "    lr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现线性回归\n",
    "1. **学习率、步长和梯度爆炸**\n",
    "    * 学习率不应该设置过大、0~1之间的数，如果过大，导致梯度爆炸（损失、参数优化成nan）\n",
    "    * 学习率越大，达到最终比较好的效果步长越小\n",
    "    * 学习率越小，达到最终比较好的效果步长越大\n",
    "    * 一般选择较小的学习率\n",
    "    \n",
    "2. **在极端条件下，权重的值变得非常大，以至于溢出，导致`NaN`值。以下是梯度爆炸解决方案（深度神经网络当中更容易出现）**\n",
    "    * 重新设计网络\n",
    "    * 调整学习率\n",
    "    * 使用梯度截断（在训练过程中检查和限制梯度的大小）\n",
    "    * 使用激活函数\n",
    "    \n",
    "3. **模型要优化的参数必须选择`tf.Variable`定义，并且指定`trainable`参数为可训练**\n",
    "\n",
    "\n",
    "4. **增加命名空间**\n",
    "\n",
    "    使代码结构更加清晰，TensorBoard图结构清楚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加变量显示\n",
    "\n",
    "目的：在TensorBoard当中观察模型的参数、损失值等变量值的变化\n",
    "\n",
    "1. 收集变量\n",
    "\n",
    "    * `tf.summary.scalar(name=\" \", tensor)`收集损失函数和准确率等单值变量，name为变量的名字，tensor为值\n",
    "    \n",
    "    * `tf.summary.histogram(name=\" \",  tensor)`收集高维度的变化参数\n",
    "    \n",
    "    * `tf.summary.image(name=\" \", tensor)`收集输入的图片张量能显示图片\n",
    "    \n",
    "2. 合并变量写入事件文件\n",
    "\n",
    "    * `merge = tf.summary.merge_all()`\n",
    "    \n",
    "    * 运行合并：`summary = sess.run(merged)`，每次迭代都需要运行\n",
    "    \n",
    "    * 添加：`FileWriter.add_summary(summary, i)` i表示第几次的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的保存与加载\n",
    "\n",
    "* `tf.train.Saver(var_list=None, max_to_keep=5)`\n",
    "    * 保存和加载模型（保存文件格式：checkpoint文件），保存要指定路径和要保存的会话\n",
    "    \n",
    "    * var_list：指定将要保存和还原的变量，它可以作为一个dict或一个列表传递\n",
    "    \n",
    "    * max_to_keep：指示要保留的最近检查点文件的最大数量。创建新文件时，会删除较旧的文件。如果无或0，则保留所有检查点文件，默认为5（即保留5个检查点文件。）\n",
    "    \n",
    "\n",
    "* `tf.Saver.restore(sess, '路径')`\n",
    "\n",
    "\n",
    "* 保存：指定路径，**指定要保存的会话**，默认保存`tf.Variable`的OP，可以指定保存哪些\n",
    "\n",
    "* 加载：本地文件的模型当中的一些变量名字与要进行加载训练的代码中的变量名字必须一致，代码训练以本地文件模型的参数值继续训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仍有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
